import os
import torch
from PIL import Image
import matplotlib.pyplot as plt
from transformers import (
    pipeline, CLIPProcessor, CLIPModel, T5Tokenizer, T5ForConditionalGeneration,
    AutoProcessor, MusicgenForConditionalGeneration, MarianMTModel, MarianTokenizer
)
import tkinter as tk
from tkinter import *
from scipy.io.wavfile import write
import hashlib
from datetime import datetime
import cv2
import numpy as np
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import threading
from pygame import mixer  # For playing audio
import time
from tkinter import *
from math import *
from tkinter.font import BOLD
from PIL import ImageTk,Image
import re
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import arabic_reshaper
from bidi.algorithm import get_display
from transformers import pipeline as emotion_pipeline
from pydub import AudioSegment  # For resampling audio
import pandas as pd
import ttkbootstrap as tb

# Initialize pygame mixer for audio playback
mixer.init()

# Input and output directories
input_dirs = r"D:\Master\Selected Topics\processed_images"
output_dir = r"D:\Master\Selected Topics\Round3\output\musicop\op2"
os.makedirs(output_dir, exist_ok=True)

# Device setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device set to: {device}")
# Fine-tuned model paths
blip_model_path = r"D:\Master\Selected Topics\Round3\Tasleem\blip_finetuned_final"
Marian_mt_finetuned=r"D:\Master\Selected Topics\MarianMT_Finetuned"
musicgen_model_path = r"D:\Master\Selected Topics\Round3\Tasleem\fine_tuned_musicgen_model"
clip_finetuned=r"D:\Master\Selected Topics\Round3\clip\clip_finetuned_final"
t5_finetuned=r"D:\Master\Selected Topics\T5_Finetuned"
# Initialize models
captioning_pipeline = pipeline("image-to-text", model=blip_model_path, device=0 if torch.cuda.is_available() else -1)
clip_processor = CLIPProcessor.from_pretrained(clip_finetuned)
clip_model = CLIPModel.from_pretrained(clip_finetuned).to(device)
t5_tokenizer = T5Tokenizer.from_pretrained(t5_finetuned)
t5_model = T5ForConditionalGeneration.from_pretrained(t5_finetuned).to(device)
musicgen_processor = AutoProcessor.from_pretrained(musicgen_model_path)
musicgen_model = MusicgenForConditionalGeneration.from_pretrained(musicgen_model_path).to(device)
tokenizer = MarianTokenizer.from_pretrained(Marian_mt_finetuned)
translation_model = MarianMTModel.from_pretrained(Marian_mt_finetuned).to(device)
# Global variable for real-time processing
real_time_active = False
############Functions###################
# Function to resample audio files to the same size
def resample_audio(audio_path, target_sample_rate=32000):
    audio = AudioSegment.from_file(audio_path)
    audio = audio.set_frame_rate(target_sample_rate)
    return audio
# Function to generate a caption using BLIP
def generate_caption(image):
    caption = captioning_pipeline(image)[0]["generated_text"]
    return caption
# Function to refine caption using CLIP
def refine_caption_with_clip(image, caption):
    inputs = clip_processor(text=[caption], images=image, return_tensors="pt", padding=True).to(device)
    outputs = clip_model(**inputs)
    logits_per_image = outputs.logits_per_image  # CLIP score
    return logits_per_image.item()
def translate_caption_arabic(image):
    caption = captioning_pipeline(image)[0]["generated_text"]
    translated = tokenizer(caption, return_tensors="pt", padding=True).to(device)
    translation = translation_model.generate(**translated)
    arabic_caption = tokenizer.decode(translation[0], skip_special_tokens=True)
    reshaped_caption = arabic_reshaper.reshape(arabic_caption)
    bidi_caption = get_display(reshaped_caption)
    return bidi_caption
# Function to check if caption matches image content using CLIP
def check_caption_match(image, caption):
    inputs = clip_processor(text=[caption], images=image, return_tensors="pt", padding=True).to(device)
    outputs = clip_model(**inputs)
    similarity_score = outputs.logits_per_image.item()  # Higher score means better match
    return similarity_score

def select_egyptian_instruments(image_description):
    # Mapping keywords to instruments
    instrument_mapping = {
        "desert": ["Oud", "Ney"],
        "camels": ["Oud", "Ney"],
        "street": ["Tabla", "Accordion"],
        "market": ["Tabla", "Accordion"],
        "mosque": ["Qanun", "Daf"],
        "pharaoh": ["Mizmar", "Arghul"],
        "river": ["Qanun", "Oud"]
    }

    # Find suitable instruments
    selected_instruments = []
    for keyword, instruments in instrument_mapping.items():
        if keyword in image_description.lower():
            selected_instruments.extend(instruments)

    # Default if no match is found
    if not selected_instruments:
        selected_instruments = ["Oud", "Tabla"]  # General Egyptian sound

    return ", ".join(set(selected_instruments))

def enhance_caption_with_egypt_music_context(caption):
    # Select suitable instruments based on the image description
    selected_instruments = select_egyptian_instruments(caption)
    # Formulate prompt for T5
    prompt = f"""
    Enhance the following image description with musical context.
    Image Description: "{caption}"
    Musical Description: Use Egyptian instruments like {selected_instruments}.
    Include traditional Egyptian rhythms (Maqsum, Baladi, Saidi).
    Use Egyptian melodic modes (maqamat) like Rast, Bayati, and Hijaz.
    """
    
    inputs = t5_tokenizer(prompt, return_tensors="pt", max_length=512, truncation=True).to(device)
    outputs = t5_model.generate(**inputs, max_length=100)
    enhanced_caption = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    return enhanced_caption
def select_general_instruments(image_description):
    # Mapping general keywords to instruments
    instrument_mapping = {
        "nature": ["Piano", "Strings"],  # Instruments associated with peaceful, natural scenes
        "city": ["Electric Guitar", "Drums"],  # Urban and energetic settings
        "beach": ["Acoustic Guitar", "Percussion"],  # Relaxed, tropical settings
        "mountain": ["Cello", "Flute"],  # Calm, majestic mountain settings
        "forest": ["Harp", "Violin"],  # Mystical or calming forest sounds
        "night": ["Saxophone", "Synthesizer"],  # Smooth, atmospheric, and cool sounds
        "party": ["Bass", "Trumpet"],  # Upbeat, energetic party sounds
        "love": ["Piano", "Violin"],  # Romantic, soft, and emotional settings
        "water": ["Marimba", "Harp"],  # Flowing, liquid, and serene sounds
        "wind": ["Flute", "Sitar"],  # Breezy and gentle winds
    }

    # Find suitable instruments
    selected_instruments = []
    for keyword, instruments in instrument_mapping.items():
        if keyword in image_description.lower():
            selected_instruments.extend(instruments)

    # Default if no match is found
    if not selected_instruments:
        selected_instruments = ["Piano", "Drums"]  # General instruments for a broad range

    return ", ".join(set(selected_instruments))


# Function to enhance caption with musical context using T5
def enhance_caption_with_music_context(caption):
    prompt = f"""
    Enhance the following image description with musical context. Include details like mood, genre, tempo, and melody:
    Image Description: "{caption}"
    Musical Description:
    """
    inputs = t5_tokenizer(prompt, return_tensors="pt", max_length=512, truncation=True).to(device)
    outputs = t5_model.generate(**inputs, max_length=100)
    enhanced_caption = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)
    return enhanced_caption

   
# Function to generate music from text using MusicGen
def generate_music_from_text(text_description, duration=10):  # Duration in seconds
    inputs = musicgen_processor(text=[text_description], padding=True, return_tensors="pt").to(device)
    with torch.no_grad():
        audio_values = musicgen_model.generate(**inputs, max_new_tokens=int(duration * 50))  # 50 tokens per second
    return audio_values

# Function to generate a unique filename
def generate_unique_filename(caption, extension=".wav"):
    hash_object = hashlib.md5(caption.encode())
    hash_hex = hash_object.hexdigest()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"output_{hash_hex}_{timestamp}{extension}"
    return filename

# Function to save and play the generated music
def save_and_play_music(audio_values, caption, sample_rate=32000, output_dir="output"):
    filename = generate_unique_filename(caption, extension=".wav")
    filepath = os.path.join(output_dir, filename)
    audio_array = audio_values.cpu().numpy().squeeze()
    write(filepath, sample_rate, audio_array)
    mixer.music.load(filepath)
    mixer.music.play()
    return filepath

# Function to save the image with captions
def save_image_with_captions(image, caption, output_dir="output"):
    filename = generate_unique_filename(caption, extension=".png")
    filepath = os.path.join(output_dir, filename)
    plt.figure(figsize=(6, 6))
    plt.imshow(image)
    plt.axis('off')
    plt.title(f"Caption: {caption}", fontsize=10)
    plt.savefig(filepath, bbox_inches="tight", pad_inches=0.1)
    plt.close()
    return filepath


# Function to merge multiple images into one
def merge_images(images):
    widths, heights = zip(*(img.size for img in images))
    total_width = sum(widths)
    max_height = max(heights)
    merged_image = Image.new('RGB', (total_width, max_height))
    x_offset = 0
    for img in images:
        merged_image.paste(img, (x_offset, 0))
        x_offset += img.size[0]
    return merged_image

# Function for real-time processing
def real_time_processing_English():
    global real_time_active
    real_time_active = True
    cap = cv2.VideoCapture(0)
    frame_count = 0
    while real_time_active:
        ret, frame = cap.read()
        if not ret:
            break
        pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        caption = generate_caption(pil_image)
       
        #genertedd_music_type=suggest_music_genre(pil_image)
        # Check if the caption matches the image content using CLIP
        similarity_score = check_caption_match(pil_image, caption)
        if similarity_score > 0.7:  # Adjust threshold as needed
            enhanced_caption = enhance_caption_with_music_context(caption)
            audio_values = generate_music_from_text(enhanced_caption, duration=10)  
            audio_filename = save_and_play_music(audio_values, enhanced_caption, output_dir=output_dir)
            image_filename = save_image_with_captions(pil_image, caption, output_dir=output_dir)
        frame_count += 1
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    cap.release()
    cv2.destroyAllWindows()
def real_time_processing_ar():
    global real_time_active
    real_time_active = True
    cap = cv2.VideoCapture(0)
    frame_count = 0
    while real_time_active:
        ret, frame = cap.read()
        if not ret:
            break
        pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        caption = generate_caption(pil_image)
        ar_caption=translate_caption_arabic(pil_image)
        
        #generated_music_type=suggest_music_genre(pil_image)
        # Check if the caption matches the image content using CLIP
        similarity_score = check_caption_match(pil_image, caption)
        if similarity_score > 0.7:  # Adjust threshold as needed
            enhanced_caption = enhance_caption_with_egypt_music_context(caption)
            audio_values = generate_music_from_text(enhanced_caption, duration=10)
            audio_filename = save_and_play_music(audio_values, enhanced_caption, output_dir=output_dir)
            image_filename = save_image_with_captions(pil_image, ar_caption, output_dir=output_dir)
        frame_count += 1
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    cap.release()
    cv2.destroyAllWindows()

# Function to process a video file
def process_video_eng(progress_bar):
    def open_file_dialog():
        video_path = filedialog.askopenfilename(
            title="Select a Video",
            filetypes=[("Video Files", "*.mp4;*.avi;*.mov;*.mkv")]
        )
        if video_path:
            try:
                progress_bar["value"] = 0
                progress_bar.update()
                cap = cv2.VideoCapture(video_path)
                frame_count = 0
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret:
                        break
                    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                    caption = generate_caption(pil_image)
                    similarity_score = check_caption_match(pil_image, caption)

                    if similarity_score > 0.7:  # Adjust threshold as needed
                        enhanced_caption = enhance_caption_with_music_context(caption)
                        audio_values = generate_music_from_text(enhanced_caption, duration=10)
                        audio_filename = save_and_play_music(audio_values, enhanced_caption, output_dir=output_dir)
                        image_filename = save_image_with_captions(pil_image, caption,output_dir=output_dir)
                    frame_count += 1
                    progress_bar["value"] = (frame_count / total_frames) * 100
                    progress_bar.update()
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                cap.release()
                cv2.destroyAllWindows()
                messagebox.showinfo("Info", f"Processing completed. Output saved in {output_dir}")
            except Exception as e:
                messagebox.showerror("Error", f"An error occurred: {e}")
            finally:
                progress_bar["value"] = 0

    # Schedule the file dialog to run in the main thread
    app.after(0, open_file_dialog)
def process_video_ar(progress_bar):
    def open_file_dialog():
        video_path = filedialog.askopenfilename(
            title="Select a Video",
            filetypes=[("Video Files", "*.mp4;*.avi;*.mov;*.mkv")]
        )
        if video_path:
            try:
                progress_bar["value"] = 0
                progress_bar.update()
                cap = cv2.VideoCapture(video_path)
                frame_count = 0
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret:
                        break
                    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                    caption = generate_caption(pil_image)
                    ar_caption=translate_caption_arabic(pil_image)
                    #generated_music_type=suggest_music_genre(pil_image)
                    similarity_score=check_caption_match(pil_image,ar_caption)
                    if similarity_score > 0.7:  # Adjust threshold as needed
                        enhanced_caption = enhance_caption_with_egypt_music_context(caption)
                        audio_values = generate_music_from_text(enhanced_caption, duration=10)
                        audio_filename = save_and_play_music(audio_values, enhanced_caption, output_dir=output_dir)
                        image_filename = save_image_with_captions(pil_image, ar_caption, output_dir=output_dir)
                    frame_count += 1
                    progress_bar["value"] = (frame_count / total_frames) * 100
                    progress_bar.update()
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                cap.release()
                cv2.destroyAllWindows()
                messagebox.showinfo("Info", f"Processing completed. Output saved in {output_dir}")
            except Exception as e:
                messagebox.showerror("Error", f"An error occurred: {e}")
            finally:
                progress_bar["value"] = 0

    # Schedule the file dialog to run in the main thread
    app.after(0, open_file_dialog)

###################GUI#############################
# Main Page
class MainPage(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("Main Page")
        self.geometry("1500x1000")
        self.config(bg='#1b3f4f')###Lon el Saf7a
        self.iconbitmap(r"D:\Master\Selected Topics\magical-music-art-colorful-notes-sharon-cummings.png")
        # Title Label
        title_label = tk.Label(self, text="Hear the Art🎨🎶🏺 ", font=("Arial", 30,"bold"),background="white",fg="#1b3f4f",width=50)
        title_label.pack(pady=20)
       # Open the image file
        img = Image.open(r"D:\Master\Selected Topics\magical-music-art-colorful-notes-sharon-cummings.png")

        # Convert the image to a Tkinter-compatible photo image
        tkimage = ImageTk.PhotoImage(img)

        # Resize the image (you can change the size as needed)
        img = img.resize((400, 400))  # Resize to 400x400 pixels

        # Convert the image to a Tkinter-compatible photo image
        tkimage = ImageTk.PhotoImage(img)

        # Create a Label widget with the resized image
        self.label = Label(self, image=tkimage)
        self.label.image = tkimage  # Keep a reference to avoid garbage collection

        # Display the image
        self.label.pack(pady=10)
        # Buttons to navigate to different pageo
        othertempobutton=tk.Button(self,text="Music from Paintings",command=self.open_english_music_gen_page,bg="#1b3f4f", fg="white",font=("Times New Roman", 20), highlightbackground="yellow",  # Background when highlighted
                   highlightcolor="red",  
                   activebackground="#d8ebf4", 
                   activeforeground="white",relief="raised",borderwidth=10,width=45,cursor="hand2")
        othertempobutton.pack(pady=10)
        egypt_music_gen_button = tk.Button(self, text=" Egyptian Music from Paintings" , command=self.open_egyptian_music_gen_page,bg="#1b3f4f", fg="white",font=("Times New Roman", 20), highlightbackground="yellow",  # Background when highlighted
                   highlightcolor="red", # 
                   activebackground="#d8ebf4" ,
                   activeforeground="white",relief="raised",borderwidth=10,width=45,cursor="hand2")
        egypt_music_gen_button.pack(pady=5)
        how_to_use_button = tk.Button(self, text="Help", 
                                      command=self.open_instructions_page ,bg="#1b3f4f", fg="white",
                                      font=("Times New Roman", 20), highlightbackground="yellow",
                                      highlightcolor="red", activebackground="#d8ebf4",
                                      activeforeground="white", relief="raised", borderwidth=10, 
                                      width=45, cursor="hand2")
        how_to_use_button.pack(pady=5)

   
    def open_english_music_gen_page(self):
        self.destroy()
        EngMusicGenPage()
    def open_egyptian_music_gen_page(self):
        self.destroy()
        EgyptMusicGenPage()
    def open_instructions_page(self):
        self.destroy()
        HowToUsePage()
        

class EgyptMusicGenPage(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title(" Egyptian Music from Paintings")
        self.geometry("1500x1000")
        self.config(bg='#1b3f4f')###Lon el Saf7a
        self.iconbitmap(r"D:\Master\Selected Topics\magical-music-art-colorful-notes-sharon-cummings.png")
        # Title Label
        title_label = tk.Label(self, text="Egyptian Music from Paintings تحويل الأعمال الفنية إلى موسيقى مصرية", font=("Arial", 24,"bold"),bg="white",fg="#1b3f4f",width=60)
        title_label.pack(pady=20)
       # Open the image file
        img = Image.open(r"D:\Master\Selected Topics\DALL·E 2025-02-07 16.25.52 - An artistic digital painting representing Egyptian music, featuring vibrant, watercolor-like textures. The artwork should include traditional Egyptian.png")

        # Convert the image to a Tkinter-compatible photo image
        tkimage = ImageTk.PhotoImage(img)

        # Resize the image (you can change the size as needed)
        img = img.resize((150, 150))  # Resize to 400x400 pixels

        # Convert the image to a Tkinter-compatible photo image
        tkimage = ImageTk.PhotoImage(img)

        # Create a Label widget with the resized image
        self.label = Label(self, image=tkimage)
        self.label.image = tkimage  # Keep a reference to avoid garbage collection

        # Display the image
        self.label.pack(pady=10)

        # Progress Bar
        self.progress_bar = ttk.Progressbar(self, orient="horizontal", length=400, mode="determinate")
        self.progress_bar.pack(pady=20)
        back_button = tk.Button(self, text="🔙", 
                                command=self.back_to_main, bg="#1b3f4f", fg="white",
                                font=("Times New Roman", 14, "bold"), relief="raised", borderwidth=3, cursor="hand2")
        back_button.place(relx=0.02, rely=0.02, anchor="nw")  # Top-left corner
        # Buttons
        select_image_button = tk.Button(self, text="Process Single Image | معالجة صورة واحدة", 
                                        command=self.process_single_image, bg="#1b3f4f", fg="white",
                                        font=("Times New Roman", 20), highlightbackground="yellow",
                                        highlightcolor="red", activebackground="#d8ebf4",
                                        activeforeground="white", relief="raised", borderwidth=10, 
                                        width=40, cursor="hand2")
        select_image_button.pack(pady=10)

        real_time_button = tk.Button(self, text="Real-Time Processing | المعالجة في الوقت الحقيقي", 
                                    command=self.start_real_time, bg="#1b3f4f", fg="white",
                                    font=("Times New Roman", 20), highlightbackground="yellow",
                                    highlightcolor="red", activebackground="#d8ebf4",
                                    activeforeground="white", relief="raised", borderwidth=10, 
                                    width=40, cursor="hand2")
        real_time_button.pack(pady=10)

        stop_real_time_button = tk.Button(self, text="Stop Real-Time Processing | إيقاف المعالجة في الوقت الحقيقي", 
                                        command=self.stop_real_time_processing, bg="#1b3f4f", fg="white",
                                        font=("Times New Roman", 20), highlightbackground="yellow",
                                        highlightcolor="red", activebackground="#d8ebf4",
                                        activeforeground="white", relief="raised", borderwidth=10, 
                                        width=40, cursor="hand2")
        stop_real_time_button.pack(pady=10)

        multiple_images_button = tk.Button(self, text="Process Multiple Images | معالجة صور متعددة", 
                                        command=self.process_multiple_images, bg="#1b3f4f", fg="white",
                                        font=("Times New Roman", 20), highlightbackground="yellow",
                                        highlightcolor="red", activebackground="#d8ebf4",
                                        activeforeground="white", relief="raised", borderwidth=10, 
                                        width=40, cursor="hand2")
        multiple_images_button.pack(pady=10)

        video_processing_button = tk.Button(self, text="Process Video | معالجة الفيديو", 
                                            command=self.process_video, bg="#1b3f4f", fg="white",
                                            font=("Times New Roman", 20), highlightbackground="yellow",
                                            highlightcolor="red", activebackground="#d8ebf4",
                                            activeforeground="white", relief="raised", borderwidth=10, 
                                            width=40, cursor="hand2")
        video_processing_button.pack(pady=10)


 

    def process_single_image(self):
        image_path = filedialog.askopenfilename(
            title="Select an Image",
            filetypes=[("Image Files", "*.jpg;*.jpeg;*.png;*.bmp;*.gif;*.tiff;*.webp")]
        )
        if image_path:
            try:
                self.progress_bar["value"] = 0
                self.progress_bar.update()
                image = Image.open(image_path)
                self.progress_bar["value"] = 25
                self.progress_bar.update()
                 # Suggest music genre using CLIP
                #suggested_genre = suggest_music_genre(image)
                caption = translate_caption_arabic(image)
                refined_caption = refine_caption_with_clip(image, caption)
                similarity_score = check_caption_match(image, caption)
                self.progress_bar["value"] = 50
                self.progress_bar.update()
                if similarity_score > 0.7:  # Adjust threshold as needed
                        enhanced_caption_music = enhance_caption_with_egypt_music_context(caption)
                        audio_values = generate_music_from_text(enhanced_caption_music, duration=10)
                        audio_filename = save_and_play_music(audio_values, enhanced_caption_music, output_dir=output_dir)
                        image_filename = save_image_with_captions(image, caption, output_dir=output_dir)
                self.progress_bar["value"] = 100
                self.progress_bar.update()
                messagebox.showinfo("Info", f"Processing completed. Output saved in {output_dir}")
            except Exception as e:
                messagebox.showerror("Error", f"An error occurred: {e}")
            finally:
                self.progress_bar["value"] = 0

    def start_real_time(self):
        global real_time_active
        if not real_time_active:
            threading.Thread(target=real_time_processing_ar).start()
        else:
            messagebox.showinfo("Info", "Real-time processing is already active.")
    def stop_real_time_processing(self):
        global real_time_active
        real_time_active = False
        messagebox.showinfo("Info", "Real-time processing stopped.")
        

    def process_multiple_images(self):
        image_paths = filedialog.askopenfilenames(
            title="Select Images",
            filetypes=[("Image Files", "*.jpg;*.jpeg;*.png;*.bmp;*.gif;*.tiff;*.webp")]
        )
        if image_paths:
            try:
                self.progress_bar["value"] = 0
                self.progress_bar.update()
                images = [Image.open(image_path) for image_path in image_paths]
                self.progress_bar["value"] = 25
                self.progress_bar.update()
                merged_image = merge_images(images)
                self.progress_bar["value"] = 50
                self.progress_bar.update()
                 # Suggest music genre using CLIP

                caption = translate_caption_arabic(merged_image)
                refine_caption=refine_caption_with_clip(merged_image,caption)
                similarity_score = check_caption_match(merged_image, caption)
                self.progress_bar["value"] = 75
                self.progress_bar.update()
                if similarity_score > 0.7:  # Adjust threshold as needed
                    enhanced_caption = enhance_caption_with_egypt_music_context(caption)
                    audio_values = generate_music_from_text(enhanced_caption, duration=10)
                    audio_filename = save_and_play_music(audio_values, enhanced_caption, output_dir=output_dir)
                    image_filename = save_image_with_captions(merged_image ,caption,output_dir=output_dir)
                self.progress_bar["value"] = 100
                self.progress_bar.update()
                messagebox.showinfo("Info", f"Processing completed. Output saved in {output_dir}")
            except Exception as e:
                messagebox.showerror("Error", f"An error occurred: {e}")
            finally:
                self.progress_bar["value"] = 0

    def process_video(self):
        threading.Thread(target=process_video_ar, args=(self.progress_bar,)).start()

    def back_to_main(self):
        self.destroy()
        MainPage()

# English Music Generation Page
class EngMusicGenPage(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("Music from Paintings")
        self.geometry("1500x1000")
        self.config(bg='#1b3f4f')###Lon el Saf7a
        self.iconbitmap(r"D:\Master\Selected Topics\magical-music-art-colorful-notes-sharon-cummings.png")
        back_button = tk.Button(self, text="🔙", 
                                command=self.back_to_main, bg="#1b3f4f", fg="white",
                                font=("Times New Roman", 14, "bold"), relief="raised", borderwidth=3, cursor="hand2")
        back_button.place(relx=0.02, rely=0.02, anchor="nw")  # Top-left corner

        # Title Label
        title_label = tk.Label(self, text="Music from Paintings", font=("Arial", 24,"bold"),bg="white",fg="#1b3f4f",width=60)
        title_label.pack(pady=20)
       # Open the image file
        img = Image.open(r"D:\Master\Selected Topics\DALL·E 2025-02-07 16.25.55 - An artistic digital painting representing non-Egyptian music, featuring vibrant, watercolor-like textures. The artwork should include Western musical .png")

        # Convert the image to a Tkinter-compatible photo image
        tkimage = ImageTk.PhotoImage(img)

        # Resize the image (you can change the size as needed)
        img = img.resize((150, 150))  # Resize to 400x400 pixels

        # Convert the image to a Tkinter-compatible photo image
        tkimage = ImageTk.PhotoImage(img)

        # Create a Label widget with the resized image
        self.label = Label(self, image=tkimage)
        self.label.image = tkimage  # Keep a reference to avoid garbage collection

        # Display the image
        self.label.pack(pady=15)

        # Progress Bar
        self.progress_bar = ttk.Progressbar(self, orient="horizontal", length=400, mode="determinate")
        self.progress_bar.pack(pady=20)
# Back 
        # Buttons
        select_image_button = tk.Button(self, text="Process Single Image", command=self.process_single_image,bg="#1b3f4f", fg="white",font=("Times New Roman", 20), highlightbackground="yellow",  # Background when highlighted
                   highlightcolor="red",  
                   activebackground="#d8ebf4", 
                   activeforeground="white",relief="raised",borderwidth=10,width=40,cursor="hand2")
        select_image_button.pack(pady=10)

        real_time_button = tk.Button(self, text="Real-Time Processing", command=self.start_real_time,bg="#1b3f4f", fg="white",font=("Times New Roman", 20), highlightbackground="yellow",  # Background when highlighted
                   highlightcolor="red",  
                   activebackground="#d8ebf4", 
                   activeforeground="white",relief="raised",borderwidth=10,width=40,cursor="hand2")
        real_time_button.pack(pady=10)
        stop_real_time_button = tk.Button(self, text="Stop Real-Time Processing", command=self.stop_real_time_processing,bg="#1b3f4f", fg="white",font=("Times New Roman", 20), highlightbackground="yellow",  # Background when highlighted
                   highlightcolor="red",  
                   activebackground="#d8ebf4", 
                   activeforeground="white",relief="raised",borderwidth=10,width=40,cursor="hand2")
        stop_real_time_button.pack(pady=10) 
        

        multiple_images_button = tk.Button(self, text="Process Multiple Images", command=self.process_multiple_images,bg="#1b3f4f", fg="white",font=("Times New Roman", 20), highlightbackground="yellow",  # Background when highlighted
                   highlightcolor="red",  
                   activebackground="#d8ebf4", 
                   activeforeground="white",relief="raised",borderwidth=10,width=40,cursor="hand2")
        multiple_images_button.pack(pady=10)

        video_processing_button = tk.Button(self, text="Process Video", command=self.process_video,bg="#1b3f4f", fg="white",font=("Times New Roman", 20), highlightbackground="yellow",  # Background when highlighted
                   highlightcolor="red",  
                   activebackground="#d8ebf4", 
                   activeforeground="white",relief="raised",borderwidth=10,width=40,cursor="hand2")
        video_processing_button.pack(pady=10)

    def process_single_image(self):
        image_path = filedialog.askopenfilename(
            title="Select an Image",
            filetypes=[("Image Files", "*.jpg;*.jpeg;*.png;*.bmp;*.gif;*.tiff;*.webp")]
        )
        if image_path:
            try:
                self.progress_bar["value"] = 0
                self.progress_bar.update()
                image = Image.open(image_path)
                self.progress_bar["value"] = 25
                self.progress_bar.update()
                caption = generate_caption(image)
                 # Suggest music genre using CLIP
                #suggested_genre = suggest_music_genre(image)
                refined_caption = refine_caption_with_clip(image, caption)
                similarity_score = check_caption_match(image, caption)
                self.progress_bar["value"] = 50
                self.progress_bar.update()
                if similarity_score > 0.7:  # Adjust threshold as needed
                    enhanced_caption_music = enhance_caption_with_music_context(caption)
                    audio_values = generate_music_from_text(enhanced_caption_music, duration=10)
                    audio_filename = save_and_play_music(audio_values, enhanced_caption_music, output_dir=output_dir)
                    image_filename = save_image_with_captions(image,caption,output_dir=output_dir)
                self.progress_bar["value"] = 100
                self.progress_bar.update()
                messagebox.showinfo("Info", f"Processing completed. Output saved in {output_dir}")
            except Exception as e:
                messagebox.showerror("Error", f"An error occurred: {e}")
            finally:
                self.progress_bar["value"] = 0

    def start_real_time(self):
        global real_time_active
        if not real_time_active:
            threading.Thread(target=real_time_processing_English).start()
        else:
            messagebox.showinfo("Info", "Real-time processing is already active.")
    def stop_real_time_processing(self):
        global real_time_active
        real_time_active = False
        messagebox.showinfo("Info", "Real-time processing stopped.")
        

    def process_multiple_images(self):
        image_paths = filedialog.askopenfilenames(
            title="Select Images",
            filetypes=[("Image Files", "*.jpg;*.jpeg;*.png;*.bmp;*.gif;*.tiff;*.webp")]
        )
        if image_paths:
            try:
                self.progress_bar["value"] = 0
                self.progress_bar.update()
                images = [Image.open(image_path) for image_path in image_paths]
                self.progress_bar["value"] = 25
                self.progress_bar.update()
                merged_image = merge_images(images)
                self.progress_bar["value"] = 50
                self.progress_bar.update()
                caption = generate_caption(merged_image)
                
                refine_caption=refine_caption_with_clip(merged_image,caption)
              
                similarity_score = check_caption_match(merged_image, caption)
        
              
                self.progress_bar["value"] = 75
                self.progress_bar.update()
                if similarity_score > 0.7:  # Adjust threshold as needed
                    enhanced_caption = enhance_caption_with_music_context(caption)
                    audio_values = generate_music_from_text(enhanced_caption, duration=10)
                    audio_filename = save_and_play_music(audio_values, enhanced_caption, output_dir=output_dir)
                    image_filename = save_image_with_captions(merged_image, caption,output_dir=output_dir)
                self.progress_bar["value"] = 100
                self.progress_bar.update()
                messagebox.showinfo("Info", f"Processing completed. Output saved in {output_dir}")
            except Exception as e:
                messagebox.showerror("Error", f"An error occurred: {e}")
            finally:
                self.progress_bar["value"] = 0


    def process_video(self):
        threading.Thread(target=process_video_eng, args=(self.progress_bar,)).start()

    def back_to_main(self):
        self.destroy()
        MainPage()

class HowToUsePage(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("How to Use the Application | كيفية استخدام التطبيق")
        self.geometry("1500x1350")
        self.config(bg="#1b3f4f")
        
        # Title Label
        back_button = tk.Button(self, text="🔙", 
                                command=self.back_to_main, bg="#1b3f4f", fg="white",
                                font=("Times New Roman", 14, "bold"), relief="raised", borderwidth=3, cursor="hand2")
        back_button.place(relx=0.02, rely=0.02, anchor="nw")  # Top-left corner

    
        title_label = tk.Label(self, text="📖 How to Use the Application | كيفية استخدام التطبيق", 
                               font=("Times New Roman", 18, "bold"), fg="#1b3f4f", bg="white")
        title_label.pack(pady=10)
  # Instructions
        instructions_en = """1️⃣ Upload an image, video, or provide real-time input. 🎨📹🎤\n"""
        instructions_en += """2️⃣ The system analyzes the input and generates a caption using BLIP & T5.\n"""
        instructions_en += """3️⃣ The caption is translated into Arabic using MarianMT. 🌍\n"""
        instructions_en += """4️⃣ CLIP retrieves matching Egyptian music, or MusicGen generates new music. 🎵\n"""
        instructions_en += """5️⃣ You can also merge two images and generate music from them. 🎭🎼\n"""
        instructions_en += """6️⃣ Listen to the generated music directly in the application. 🎧"""
        
        instructions_ar = """1️⃣ قم بتحميل صورة أو فيديو أو إدخال صوتي مباشر. 🎨📹🎤\n"""
        instructions_ar += """2️⃣ يقوم النظام بتحليل المدخلات وإنشاء وصف باستخدام BLIP و T5.\n"""
        instructions_ar += """3️⃣ يتم ترجمة الوصف إلى العربية باستخدام MarianMT. 🌍\n"""
        instructions_ar += """4️⃣ يقوم CLIP بجلب الموسيقى المصرية المناسبة، أو يستخدم MusicGen لتوليد موسيقى جديدة. 🎵\n"""
        instructions_ar += """5️⃣ يمكنك أيضًا دمج صورتين وإنشاء موسيقى منهما. 🎭🎼\n"""
        instructions_ar += """6️⃣ استمع إلى الموسيقى المولدة مباشرة في التطبيق. 🎧"""

        instructions_label = tk.Label(self, text=f"{instructions_en}\n\n{instructions_ar}", 
                                      font=("Times New Roman", 14), fg="#1b3f4f", bg="white", justify="left")
        instructions_label.pack(pady=10)

        # AI Models Used
        ai_models_label = tk.Label(self,text="👥 Who Uses the Application | من يستخدم التطبيق", 
                                   font=("Times New Roman", 18, "bold"), fg="#1b3f4f", bg="white")
        ai_models_label.pack(pady=10)

        ai_models_text_en = """
    - Artists and art enthusiasts exploring Egyptian culture.
    - Musicians and composers seeking inspiration from Egyptian heritage.
    - Researchers studying the connection between visual art and music.
    - AI and deep learning enthusiasts interested in generative models.
    - Museums and educational institutions for cultural preservation.
    - Therapists using art therapy to aid emotional expression.
    - Tourist attractions for immersive cultural experiences."""
            
        ai_models_text_ar =  """
    - الفنانين وعشاق الفن الذين يستكشفون الثقافة المصرية.
    - الموسيقيين والملحنين الباحثين عن الإلهام من التراث المصري.
    - الباحثين الذين يدرسون العلاقة بين الفن البصري والموسيقى.
    - المهتمين بالذكاء الاصطناعي والتعلم العميق ونماذج التوليد.
    - المتاحف والمؤسسات التعليمية للحفاظ على الثقافة.
    - المعالجين بالفن لمساعدة المرضى على التعبير عن مشاعرهم.
    - الأماكن السياحية لتجارب ثقافية غامرة."""


        ai_models_label_text = tk.Label(self, text=f"{ai_models_text_en}\n\n{ai_models_text_ar}", 
                                        font=("Times New Roman", 14), fg="#1b3f4f", bg="white", 
                                        justify="left")
        ai_models_label_text.pack(pady=10)

    def back_to_main(self):
            self.destroy()
            MainPage()

   
# Entry point
if __name__ == "__main__":
    app = MainPage()
    app.mainloop()

